#!/bin/sh
## This names the job for the queueing system
#PBS -N reinf_learn
## This denotes the queue that the job should be run in.
#PBS -A stats_flux
#PBS -l qos=flux
#PBS -q flux

## This denotes the number of nodes and processors that the job should be run on.
## For embarrassingly parallel computing, instead select the number of processors
## 4 processors, on one node, 4 gigs mem per node
## Note this wont run with gpu
#PBS -l nodes=1:ppn=2,walltime=10:00:00,pmem=8GB

## Where does your program's STDOUT go? (Replace with your uniquemane)
#PBS -o /home/ataxali/stats551/Bayesian_Reinforcement_Learning.git/trunk

## Import the shell's environment
## This is important if you're using Environment Modules (i.e. module load ...)
#PBS -V

## In what circumstances should an email be sent regarding this job?  'a' is for aborted jobs,
## 'b' is when the job starts, and 'e' is when the job exits.
#PBS -m abe

## Where should email be sent when the job starts and stops? REPLACE with your uniquename.
#PBS -M ataxali@umich.edu

#PBS -j oe
#PBS -t 1-10

## Code to be run
python /home/ataxali/stats551/Bayesian_Reinforcement_Learning.git/trunk/componentTesters.py name=bayes_opt batch_id=${PBS_ARRAYID} move_limit=100 > /home/ataxali/stats551/Bayesian_Reinforcement_Learning.git/trunk/batch_opt${PBS_ARRAYID}_train.txt


